{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c77ac803-c2b7-4833-b411-0d09bbdeff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from UNet_m import ResBlock,Encoder,Decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3d69f455-ccfb-451e-ae4b-c2af8ca86a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "torch.Size([1, 1, 257, 10])\n",
      "torch.Size([1, 1, 257, 10])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "matched channels\n",
    "multi-scale Global feature \n",
    "\"\"\"\n",
    "class ResUNetOnFreq3(nn.Module) :\n",
    "    def __init__(self, \n",
    "                 c_in = 1,\n",
    "                 c_out = 1,\n",
    "                 n_fft=512,\n",
    "                 device=\"cuda:0\",\n",
    "                 print_shape=False,\n",
    "                 n_block = 5,\n",
    "                 activation = \"Softplus\" , \n",
    "                 Softplus_thr = 20,\n",
    "                 norm = \"BatchNorm2d\",\n",
    "                 dropout = 0.0\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        n_hfft = int(n_fft/2+1)\n",
    "\n",
    "        self.print_shape=print_shape\n",
    "\n",
    "        self.F = n_hfft\n",
    "        f_dim = 30\n",
    "        \n",
    "        upscale = [1,2.2, 4.5, 9, 18.4, 36.8]\n",
    "\n",
    "        if n_block < 2 :\n",
    "            raise Exception(\"ERROR::ResUnetOnFreq : n_block({}) < 2\".fomrat(n_block))\n",
    "\n",
    "        ## Model Implementation\n",
    "\n",
    "        # input layer\n",
    "        self.layer_input = nn.Sequential(\n",
    "            Encoder(c_in,f_dim,(1,3),1,(0,1),1),\n",
    "            nn.LayerNorm(n_hfft) \n",
    "        )\n",
    "\n",
    "        # Encoder\n",
    "        encoders=[]\n",
    "        encoders.append(ResBlock(f_dim))\n",
    "        for i in range(n_block) :\n",
    "            encoders.append(nn.Sequential(\n",
    "                    Encoder(f_dim,f_dim,(3,1),\n",
    "                    (2,1),(0,0),activation=\"PReLU\",norm=norm),\n",
    "                    ResBlock(30)))\n",
    "\n",
    "        self.encoders=encoders\n",
    "        for i,enc in enumerate(self.encoders) : \n",
    "            self.add_module(\"enc_{}\".format(i),enc)\n",
    "        \n",
    "        # multi-scale encoder\n",
    "        ms = []\n",
    "        for i in range(n_block):\n",
    "            ms.append(nn.Sequential(\n",
    "                nn.Conv2d(30,30,(2**(n_block+1-i),1),stride=(2**(n_block-i),1),padding=(1,0))\n",
    "            ))\n",
    "        self.ms = ms\n",
    "        for i,i_ms in enumerate(self.ms) : \n",
    "            self.add_module(\"ms_{}\".format(i),i_ms)\n",
    "            \n",
    "        self.upsample = []\n",
    "        for scale in upscale : \n",
    "            self.upsample.append(nn.Sequential(\n",
    "                            nn.Upsample(scale_factor=(scale,1), mode='nearest'),\n",
    "                            nn.Sigmoid()\n",
    "            ))\n",
    "        for i,i_up in enumerate(self.upsample) : \n",
    "            self.add_module(\"up_{}\".format(i),i_up)\n",
    "            \n",
    "        # Decoder\n",
    "        decoders=[]\n",
    "        for i in range(n_block-2) :\n",
    "            decoders.append(nn.Sequential(\n",
    "                ResBlock(f_dim),\n",
    "                Decoder(f_dim,f_dim,(4,1),\n",
    "                (2,1),(1,0),output_padding=(1,0),activation=\"PReLU\",norm=norm)))\n",
    "        decoders.append(nn.Sequential(\n",
    "                ResBlock(f_dim),\n",
    "                Decoder(f_dim,f_dim,(5,1),\n",
    "                (2,1),(1,0),output_padding=(1,0),activation=\"PReLU\",norm=norm)))\n",
    "        decoders.append(nn.Sequential(\n",
    "                ResBlock(f_dim),\n",
    "                Decoder(f_dim,f_dim,(4,1),\n",
    "                (2,1),(1,0),output_padding=(1,0),activation=\"PReLU\",norm=norm)))\n",
    "        decoders.append(ResBlock(f_dim))\n",
    "\n",
    "        self.decoders=decoders\n",
    "        for i,dec in enumerate(self.decoders) : \n",
    "            self.add_module(\"dec_{}\".format(i),dec)\n",
    "\n",
    "        self.len_model = len(encoders)\n",
    "\n",
    "        # Residual Path\n",
    "        res_paths = []\n",
    "        res_paths.append(Encoder(f_dim,f_dim,1,1,0,1,activation=\"PReLU\"))\n",
    "        for i in range(n_block) : \n",
    "            res_paths.append(Encoder(f_dim,f_dim,1,1,0,1,activation=\"PReLU\"))\n",
    "\n",
    "        self.res_paths = res_paths\n",
    "        for i,res_path in enumerate(self.res_paths) : \n",
    "            self.add_module(\"res_path_{}\".format(i),res_path)\n",
    "\n",
    "        # Bottlenect\n",
    "        self.bottleneck = nn.LSTM(210,300,3,batch_first=True,proj_size=210,dropout=dropout)\n",
    "\n",
    "        # output layer\n",
    "        self.out_layer = nn.ConvTranspose2d(f_dim,c_out,(3,1),stride=1,padding=(1,0),dilation=1,output_padding=(0,0))\n",
    "\n",
    "        if activation == \"Softplus\" : \n",
    "            self.activation_mask = nn.Softplus(threshold=Softplus_thr)\n",
    "        elif activation == \"Sigmoid\" : \n",
    "            self.activation_mask = nn.Sigmoid()\n",
    "        else : \n",
    "            self.activation_mask = nn.Softplus()\n",
    "\n",
    "    def forward(self,input):\n",
    "        ## ipnut : [ Batch Channel Freq Time]\n",
    "        # reshape\n",
    "        # [ B C T F]\n",
    "        feature = torch.permute(input[:,:,:,:],(0,1,3,2))\n",
    "        feature = self.layer_input(feature)\n",
    "\n",
    "        # reshape\n",
    "        x = torch.permute(feature,(0,1,3,2))\n",
    "\n",
    "        ## Encoder\n",
    "        res=[]\n",
    "        \n",
    "        ## Multi-Scale Feature\n",
    "        \n",
    "        ms = None\n",
    "        for i,enc in enumerate(self.encoders):\n",
    "            x = enc(x)\n",
    "            if self.print_shape : \n",
    "                print(\"x_{} : {}\".format(i,x.shape))\n",
    "            res.append(x)\n",
    "            \n",
    "            if i < len(self.ms) :\n",
    "                if ms is None : \n",
    "                    ms = self.ms[i](x)\n",
    "                else : \n",
    "                    ms += self.ms[i](x)\n",
    "                if self.print_shape : \n",
    "                    print(\"ms_{} : {}\".format(i,ms.shape))\n",
    "        \n",
    "        ## bottleneck\n",
    "        # [B,C,F',T] -> [B,C*F',T]\n",
    "        d0,d1,d2,d3 = x.shape\n",
    "        x = torch.reshape(x,(x.shape[0],x.shape[1]*x.shape[2],x.shape[3]))\n",
    "        # [B,C,T] -> [B,T,C]\n",
    "        x = torch.permute(x,(0,2,1))\n",
    "        #print(\"bottle in : {}\".format(x.shape))\n",
    "\n",
    "        x = self.bottleneck(x)[0]\n",
    "\n",
    "        # [B,T,C] -> [B,C,T]\n",
    "        x = torch.permute(x,(0,2,1))\n",
    "        # [B,C,T] -> [B,C,1,T]\n",
    "        x = torch.reshape(x,(d0,d1,d2,d3))\n",
    "        \n",
    "        ## ResPath\n",
    "        for i,res_path in enumerate(self.res_paths) : \n",
    "            res[i] = res_path(res[i])\n",
    "        \n",
    "\n",
    "        ## Decoder\n",
    "\n",
    "        y = x\n",
    "        for i,dec in enumerate(self.decoders) : \n",
    "            if self.print_shape : \n",
    "                print(\"y : {} += r_{}*att_{} : {}\".format(y.shape,i,i,res[-1-i].shape))\n",
    "            \n",
    "            up = self.upsample[i]\n",
    "            att = up(ms)\n",
    "            \n",
    "            y  = torch.add(y,res[-1-i]*att)\n",
    "            y = dec(y)\n",
    "            if self.print_shape : \n",
    "                print(\"-> y_{} : {}\".format(i,y.shape))\n",
    "\n",
    "        ## output\n",
    "        \n",
    "        output = self.out_layer(y)\n",
    "        return self.activation_mask(output)\n",
    "    \n",
    "\n",
    "m = ResUNetOnFreq3(c_in = 1, print_shape=True, activation = \"Sigmoid\")\n",
    "m.eval()\n",
    "\n",
    "# to check low latency\n",
    "x = torch.rand(1,1,257,1)\n",
    "m(x)\n",
    "print(\"--------------------\")\n",
    "\n",
    "x = torch.rand(1,1,257,10)\n",
    "print(x.shape)\n",
    "y = m(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329162dd-2cc0-4c97-8b21-295ed3023a77",
   "metadata": {},
   "source": [
    "## Upsample\n",
    "\n",
    "```\n",
    "x_0 : torch.Size([1, 30, 257, 1])\n",
    "x_1 : torch.Size([1, 30, 128, 1])\n",
    "x_2 : torch.Size([1, 30, 63, 1])\n",
    "x_3 : torch.Size([1, 30, 31, 1])\n",
    "x_4 : torch.Size([1, 30, 15, 1])\n",
    "x_5 : torch.Size([1, 30, 7, 1])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5dc7dafb-7927-4114-b346-cb01d57592bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 7, 10])\n",
      "torch.Size([1, 30, 15, 10])\n",
      "torch.Size([1, 30, 31, 10])\n",
      "torch.Size([1, 30, 63, 10])\n",
      "torch.Size([1, 30, 128, 10])\n",
      "torch.Size([1, 30, 257, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1,30,7,10)\n",
    "print(x.shape)\n",
    "\n",
    "m = nn.Upsample(scale_factor=(2.2,1), mode='nearest')\n",
    "y = m(x)\n",
    "print(y.shape)\n",
    "\n",
    "m = nn.Upsample(scale_factor=(4.5,1), mode='nearest')\n",
    "y = m(x)\n",
    "print(y.shape)\n",
    "\n",
    "m = nn.Upsample(scale_factor=(9,1), mode='nearest')\n",
    "y = m(x)\n",
    "print(y.shape)\n",
    "\n",
    "m = nn.Upsample(scale_factor=(18.4,1), mode='nearest')\n",
    "y = m(x)\n",
    "print(y.shape)\n",
    "\n",
    "m = nn.Upsample(scale_factor=(36.8,1), mode='nearest')\n",
    "y = m(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cb31fb-17ea-4ff5-997c-04e37073e135",
   "metadata": {},
   "source": [
    "## multi-scale encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6f81cad-29b3-41c8-8acd-ed62ae31a045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 257, 1])\n",
      "torch.Size([1, 30, 7, 1])\n",
      "torch.Size([1, 30, 15, 1])\n",
      "torch.Size([1, 30, 7, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1,30,257,1)\n",
    "m = torch.nn.Conv2d(30,30,(64,1),stride=(32,1))\n",
    "y = m(x)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "x = torch.rand(1,30,15,1)\n",
    "m = torch.nn.Conv2d(30,30,(3,1),stride=(2,1))\n",
    "y = m(x)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8723f4-1843-4717-b151-313587b2c9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
