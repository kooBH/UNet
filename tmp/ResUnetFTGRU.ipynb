{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "15c88c16-74e5-490d-afc1-3cb68e3cf819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from UNet_m import ResBlock,Encoder,Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dcf00d09-e280-4f0f-a143-6090ed9d6a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseSeparableConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(DepthwiseSeparableConv2d, self).__init__()\n",
    "        \n",
    "        self.depthwise = nn.Conv2d(\n",
    "            in_channels=in_channels,  # because it passed already in the previous conv\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            groups=in_channels,\n",
    "        )\n",
    "        self.bn_depth = nn.BatchNorm2d(out_channels)\n",
    "        self.pointwise = nn.Conv2d(out_channels, out_channels, kernel_size=1)\n",
    "        self.bn_point = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.bn_depth(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.pointwise(x)\n",
    "        x = self.bn_point(x)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "From https://github.com/JusperLee/AFRCNN-For-Speech-Separation\n",
    "\"\"\"\n",
    "class GlobalChannelLayerNorm(nn.Module):\n",
    "    '''\n",
    "        Global Layer Normalization\n",
    "    '''\n",
    "    def __init__(self, channel_size):\n",
    "        super(GlobalChannelLayerNorm, self).__init__()\n",
    "        self.channel_size = channel_size\n",
    "        self.gamma = nn.Parameter(torch.ones(channel_size),\n",
    "                                  requires_grad=True)\n",
    "        self.beta = nn.Parameter(torch.zeros(channel_size),\n",
    "                                 requires_grad=True)\n",
    "    \n",
    "    def apply_gain_and_bias(self, normed_x):\n",
    "        \"\"\" Assumes input of size `[batch, chanel, *]`. \"\"\"\n",
    "        return (self.gamma * normed_x.transpose(1, -1) +\n",
    "                self.beta).transpose(1, -1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: N x C x T\n",
    "        \"\"\"\n",
    "        dims = list(range(1, len(x.shape)))\n",
    "        mean = x.mean(dim=dims, keepdim=True)\n",
    "        var = torch.pow(x - mean, 2).mean(dim=dims, keepdim=True)\n",
    "        return self.apply_gain_and_bias((x - mean) / (var + 1e-8).sqrt())\n",
    "\"\"\"\n",
    "Modified FFN Block of  \n",
    "Li, Kai, Runxuan Yang, and Xiaolin Hu. \n",
    "\"An efficient encoder-decoder architecture with top-down attention for speech separation.\"\n",
    "arXiv preprint arXiv:2209.15200 (2022).\n",
    "\n",
    "\"\"\"\n",
    "class MultiScaleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels) : \n",
    "        super(MultiScaleConvBlock, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, in_channels*2, kernel_size=1),\n",
    "                    GlobalChannelLayerNorm(in_channels*2),\n",
    "                    DepthwiseSeparableConv2d(in_channels*2, in_channels*2, kernel_size=1),\n",
    "                    GlobalChannelLayerNorm(in_channels*2),\n",
    "                    nn.Conv2d(in_channels*2, in_channels, kernel_size=1),\n",
    "                    GlobalChannelLayerNorm(in_channels)\n",
    "        \n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x : [B, C, F, T]\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "class LSTMBlock(nn.Module):\n",
    "    def __init__(self,n_dim,n_hidden,n_layer=3,proj_size=None,dropout=0.2) : \n",
    "        super(LSTMBlock, self).__init__()\n",
    "        \n",
    "        if proj_size == None :\n",
    "            proj_size = n_dim\n",
    "        self.rnn = nn.LSTM(n_dim,n_hidden,n_layer,batch_first=True,proj_size=proj_size,dropout=dropout)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # [B,C,F',T] -> [B,C*F',T]\n",
    "        d0,d1,d2,d3 = x.shape\n",
    "        x = torch.reshape(x,(x.shape[0],x.shape[1]*x.shape[2],x.shape[3]))\n",
    "        # [B,C*F',T] -> [B,T,C*F']\n",
    "        x = torch.permute(x,(0,2,1))\n",
    "        #print(\"bottle in : {}\".format(x.shape))\n",
    "\n",
    "        x,h = self.rnn(x)\n",
    "\n",
    "        # [B,T,C*F'] -> [B,C*F',T]\n",
    "        x = torch.permute(x,(0,2,1))\n",
    "        # [B,C*F',T] -> [B,C,F',T]\n",
    "        x = torch.reshape(x,(d0,d1,d2,d3))\n",
    "        \n",
    "        return x,h\n",
    "    \n",
    "\n",
    "class FGRUBlock(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_size, out_channels):\n",
    "        super(FGRUBlock, self).__init__()\n",
    "        self.GRU = nn.GRU(\n",
    "            in_channels, hidden_size, batch_first=True, bidirectional=True\n",
    "        )\n",
    "        # the GRU is bidirectional -> multiply hidden_size by 2\n",
    "        self.conv = nn.Conv2d(hidden_size * 2, out_channels, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # X : [B, C, F', T]\n",
    "        # goal : [BT, F, C ]\n",
    "        B, C, T, F_ = x.shape\n",
    "        x_ = x.permute(0, 2, 3, 1)  # x_.shape == (B,T,F,C)\n",
    "        x_ = x_.reshape(B * T, F_, C)\n",
    "        y, h = self.GRU(x_)  # x_.shape == (BT,F,C)\n",
    "        y = y.reshape(B, T, F_, self.hidden_size * 2)\n",
    "        output = y.permute(0, 3, 1, 2)  # output.shape == (B,C,T,F)\n",
    "        output = self.conv(output)\n",
    "        output = self.bn(output)\n",
    "        return self.relu(output)\n",
    "\n",
    "\n",
    "class TGRUBlock(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_size, out_channels):\n",
    "        super(TGRUBlock, self).__init__()\n",
    "        self.GRU = nn.GRU(in_channels, hidden_size, batch_first=True)\n",
    "        self.conv = nn.Conv2d(hidden_size, out_channels, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, rnn_state=None):\n",
    "        \"\"\"\n",
    "        X :[B, C, F', T]\n",
    "        \n",
    "        X' : [B*F', T, C']\n",
    "        \"\"\"\n",
    "        B, C, F_, T = x.shape\n",
    " \n",
    "        # -> [B, F', T, C]\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        # -> [B*F', T, C]\n",
    "        x = x.reshape(B * F_, T, C)\n",
    " \n",
    "            \n",
    "        x, rnn_state = self.GRU(x, rnn_state)  # y_.shape == (BF,T,C)\n",
    "        #  X' : [B*F', T, hidden_size]\n",
    "        # -> X' : [B, F', T, hidden_size]\n",
    "        print(\"TGRU::{}\".format(x.shape))\n",
    "        x = x.reshape(B, F_, T, self.hidden_size)\n",
    "        # -> X' : [B, hidden_size, F', T]\n",
    "        x = x.permute(0, 3, 1, 2)     \n",
    "        #  X' : [B, C, F', T]\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x, rnn_state\n",
    "\n",
    "class ResUNetOnFreq2(nn.Module) :\n",
    "    def __init__(self, \n",
    "                 c_in = 1,\n",
    "                 c_out = 1,\n",
    "                 n_fft=512,\n",
    "                 device=\"cuda:0\",\n",
    "                 print_shape=False,\n",
    "                 n_block = 5,\n",
    "                 activation = \"Softplus\" , \n",
    "                 bottleneck = \"LSTM\",\n",
    "                 Softplus_thr = 20,\n",
    "                 norm = \"BatchNorm2d\",\n",
    "                 dropout = 0.0,\n",
    "                 activation_layer = \"PReLU\",\n",
    "                 multi_scale = False\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        n_hfft = int(n_fft/2+1)\n",
    "\n",
    "        self.print_shape=print_shape\n",
    "        self.activation = activation\n",
    "        self.multi_scale = multi_scale\n",
    "        self.F = n_hfft\n",
    "        upscale = [1,2.2, 4.5, 9, 18.4, 36.8]\n",
    "        f_dim = 30\n",
    "\n",
    "        if n_block < 2 :\n",
    "            raise Exception(\"ERROR::ResUnetOnFreq : n_block({}) < 2\".fomrat(n_block))\n",
    "\n",
    "        ## Model Implementation\n",
    "\n",
    "        # input layer\n",
    "        self.layer_input = nn.Sequential(\n",
    "            Encoder(c_in,f_dim,(1,3),1,(0,1),1),\n",
    "            nn.LayerNorm(n_hfft) \n",
    "        )\n",
    "\n",
    "        # Encoder\n",
    "        encoders=[]\n",
    "        encoders.append(ResBlock(f_dim))\n",
    "        for i in range(n_block) :\n",
    "            encoders.append(nn.Sequential(\n",
    "                    Encoder(f_dim,f_dim,(3,1),\n",
    "                    (2,1),(0,0),activation=activation_layer,norm=norm),\n",
    "                    ResBlock(30)))\n",
    "\n",
    "        self.encoders=encoders\n",
    "        for i,enc in enumerate(self.encoders) : \n",
    "            self.add_module(\"enc_{}\".format(i),enc)\n",
    "\n",
    "        # Decoder\n",
    "        decoders=[]\n",
    "        for i in range(n_block-2) :\n",
    "            decoders.append(nn.Sequential(\n",
    "                ResBlock(f_dim),\n",
    "                Decoder(f_dim,f_dim,(4,1),\n",
    "                (2,1),(1,0),output_padding=(1,0),activation=activation_layer,norm=norm)))\n",
    "        decoders.append(nn.Sequential(\n",
    "                ResBlock(f_dim),\n",
    "                Decoder(f_dim,f_dim,(5,1),\n",
    "                (2,1),(1,0),output_padding=(1,0),activation=activation_layer,norm=norm)))\n",
    "        decoders.append(nn.Sequential(\n",
    "                ResBlock(f_dim),\n",
    "                Decoder(f_dim,f_dim,(4,1),\n",
    "                (2,1),(1,0),output_padding=(1,0),activation=activation_layer,norm=norm)))\n",
    "        decoders.append(ResBlock(f_dim))\n",
    "\n",
    "        self.decoders=decoders\n",
    "        for i,dec in enumerate(self.decoders) : \n",
    "            self.add_module(\"dec_{}\".format(i),dec)\n",
    "\n",
    "        self.len_model = len(encoders)\n",
    "\n",
    "        # Residual Path\n",
    "        res_paths = []\n",
    "        res_paths.append(Encoder(f_dim,f_dim,1,1,0,1,activation=activation_layer))\n",
    "        for i in range(n_block) : \n",
    "            res_paths.append(Encoder(f_dim,f_dim,1,1,0,1,activation=activation_layer))\n",
    "\n",
    "        self.res_paths = res_paths\n",
    "        for i,res_path in enumerate(self.res_paths) : \n",
    "            self.add_module(\"res_path_{}\".format(i),res_path)\n",
    "\n",
    "        # Bottleneck\n",
    "        if bottleneck == \"LSTM\" : \n",
    "            self.bottleneck = LSTMBlock(210,300,n_layer=3,dropout=dropout)\n",
    "        elif bottleneck == \"FTGRU\" : \n",
    "            bottleneck_hidden = 256\n",
    "            bottleneck_channel = f_dim*2\n",
    "            self.bottleneck = nn.Sequential(\n",
    "                FGRUBlock(f_dim, bottleneck_hidden, bottleneck_channel),\n",
    "                TGRUBlock(bottleneck_channel, bottleneck_hidden, f_dim)\n",
    "            )            \n",
    "        else :\n",
    "            self.bottleneck = nn.LSTM(210,300,3,batch_first=True,proj_size=210,dropout=dropout)\n",
    "            \n",
    "        # multi-scale encoder\n",
    "        if multi_scale : \n",
    "            ms = []\n",
    "            for i in range(n_block):\n",
    "                ms.append(nn.Sequential(\n",
    "                    #nn.Conv2d(30,30,(2**(n_block+1-i),1),stride=(2**(n_block-i),1),padding=(1,0))\n",
    "                    nn.AvgPool2d((2**(n_block+1-i),1),stride=(2**(n_block-i),1),padding=(1,0))\n",
    "                ))\n",
    "            self.ms = ms\n",
    "            for i,i_ms in enumerate(self.ms) : \n",
    "                self.add_module(\"ms_{}\".format(i),i_ms)\n",
    "                \n",
    "            self.ms_module = MultiScaleConvBlock(f_dim)\n",
    "\n",
    "            self.upsample = []\n",
    "            for scale in upscale : \n",
    "                self.upsample.append(nn.Sequential(\n",
    "                                nn.Upsample(scale_factor=(scale,1), mode='nearest'),\n",
    "                                nn.Sigmoid()\n",
    "                ))\n",
    "            for i,i_up in enumerate(self.upsample) : \n",
    "                self.add_module(\"up_{}\".format(i),i_up)\n",
    "\n",
    "        # output layer\n",
    "        self.out_layer = nn.ConvTranspose2d(f_dim,c_out,(3,1),stride=1,padding=(1,0),dilation=1,output_padding=(0,0))\n",
    "\n",
    "        if activation == \"Softplus\" : \n",
    "            self.activation_mask = nn.Softplus(threshold=Softplus_thr)\n",
    "        elif activation == \"Sigmoid\" : \n",
    "            self.activation_mask = nn.Sigmoid()\n",
    "        elif activation == \"Tanh\" : \n",
    "            self.activation_mask = nn.Tanh()\n",
    "        elif activation == \"Identity\" : \n",
    "            self.activation_mask = nn.Identity()\n",
    "        elif activation == \"MEA\" : \n",
    "            if c_in == 1 :\n",
    "                raise Exception(\"ERROR::ResUnetOnFreq::feature must be complex\")\n",
    "            self.activation_mask = MEA(in_channels = c_out)\n",
    "            self.add_module(\"MEA\",self.activation_mask)\n",
    "        else : \n",
    "            self.activation_mask = nn.Softplus()\n",
    "\n",
    "    def forward(self,input):\n",
    "        ## ipnut : [ Batch Channel Freq Time]\n",
    "        # reshape\n",
    "        # [ B C T F]\n",
    "        feature = torch.permute(input[:,:,:,:],(0,1,3,2))\n",
    "        feature = self.layer_input(feature)\n",
    "\n",
    "        # reshape\n",
    "        x = torch.permute(feature,(0,1,3,2))\n",
    "\n",
    "        ## Encoder\n",
    "        res = []\n",
    "        ms = None\n",
    "        for i,enc in enumerate(self.encoders):\n",
    "            x = enc(x)\n",
    "            if self.print_shape : \n",
    "                print(\"x_{} : {}\".format(i,x.shape))\n",
    "            res.append(x)\n",
    "            \n",
    "            # multi-scale\n",
    "            if self.multi_scale and i < len(self.ms) :\n",
    "                if ms is None : \n",
    "                    ms = self.ms[i](x)\n",
    "                else : \n",
    "                    ms += self.ms[i](x)\n",
    "                if self.print_shape : \n",
    "                    print(\"ms_{} : {}\".format(i,ms.shape))\n",
    "                ms = self.ms_module(ms)\n",
    "\n",
    "        ## bottleneck\n",
    "        x = self.bottleneck(x)[0]\n",
    "\n",
    "        ## ResPath\n",
    "        for i,res_path in enumerate(self.res_paths) : \n",
    "            res[i] = res_path(res[i])\n",
    "\n",
    "        ## Decoder\n",
    "        y = x\n",
    "\n",
    "        for i,dec in enumerate(self.decoders) : \n",
    "            if self.print_shape : \n",
    "                print(\"y {} += r_{} : {}\".format(y.shape,i,res[-1-i].shape))\n",
    "                \n",
    "            if self.multi_scale : \n",
    "                up = self.upsample[i]\n",
    "                att = up(ms)\n",
    "                y  = torch.add(y,res[-1-i]*att)\n",
    "            else : \n",
    "                y  = torch.add(y,res[-1-i])\n",
    "                \n",
    "            y = dec(y)\n",
    "            if self.print_shape : \n",
    "                print(\"y_{} : {}\".format(i,y.shape))     \n",
    "\n",
    "        ## output\n",
    "        output = self.out_layer(y)\n",
    "        return self.activation_mask(output)\n",
    "\n",
    "    def output(self,mask,feature):\n",
    "\n",
    "        if self.activation == \"MEA\" : \n",
    "            return self.last_activation.output(mask,feature)\n",
    "        else :\n",
    "            return mask * feature[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b225b711-99bd-4f9b-8dc1-95d7c5074556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_0 : torch.Size([1, 30, 257, 1])\n",
      "ms_0 : torch.Size([1, 30, 7, 1])\n",
      "x_1 : torch.Size([1, 30, 128, 1])\n",
      "ms_1 : torch.Size([1, 30, 7, 1])\n",
      "x_2 : torch.Size([1, 30, 63, 1])\n",
      "ms_2 : torch.Size([1, 30, 7, 1])\n",
      "x_3 : torch.Size([1, 30, 31, 1])\n",
      "ms_3 : torch.Size([1, 30, 7, 1])\n",
      "x_4 : torch.Size([1, 30, 15, 1])\n",
      "ms_4 : torch.Size([1, 30, 7, 1])\n",
      "x_5 : torch.Size([1, 30, 7, 1])\n",
      "TGRU::torch.Size([7, 1, 256])\n",
      "y torch.Size([1, 30, 7, 1]) += r_0 : torch.Size([1, 30, 7, 1])\n",
      "y_0 : torch.Size([1, 30, 15, 1])\n",
      "y torch.Size([1, 30, 15, 1]) += r_1 : torch.Size([1, 30, 15, 1])\n",
      "y_1 : torch.Size([1, 30, 31, 1])\n",
      "y torch.Size([1, 30, 31, 1]) += r_2 : torch.Size([1, 30, 31, 1])\n",
      "y_2 : torch.Size([1, 30, 63, 1])\n",
      "y torch.Size([1, 30, 63, 1]) += r_3 : torch.Size([1, 30, 63, 1])\n",
      "y_3 : torch.Size([1, 30, 128, 1])\n",
      "y torch.Size([1, 30, 128, 1]) += r_4 : torch.Size([1, 30, 128, 1])\n",
      "y_4 : torch.Size([1, 30, 257, 1])\n",
      "y torch.Size([1, 30, 257, 1]) += r_5 : torch.Size([1, 30, 257, 1])\n",
      "y_5 : torch.Size([1, 30, 257, 1])\n",
      "--------------------\n",
      "torch.Size([1, 1, 257, 10])\n",
      "x_0 : torch.Size([1, 30, 257, 10])\n",
      "ms_0 : torch.Size([1, 30, 7, 10])\n",
      "x_1 : torch.Size([1, 30, 128, 10])\n",
      "ms_1 : torch.Size([1, 30, 7, 10])\n",
      "x_2 : torch.Size([1, 30, 63, 10])\n",
      "ms_2 : torch.Size([1, 30, 7, 10])\n",
      "x_3 : torch.Size([1, 30, 31, 10])\n",
      "ms_3 : torch.Size([1, 30, 7, 10])\n",
      "x_4 : torch.Size([1, 30, 15, 10])\n",
      "ms_4 : torch.Size([1, 30, 7, 10])\n",
      "x_5 : torch.Size([1, 30, 7, 10])\n",
      "TGRU::torch.Size([7, 10, 256])\n",
      "y torch.Size([1, 30, 7, 10]) += r_0 : torch.Size([1, 30, 7, 10])\n",
      "y_0 : torch.Size([1, 30, 15, 10])\n",
      "y torch.Size([1, 30, 15, 10]) += r_1 : torch.Size([1, 30, 15, 10])\n",
      "y_1 : torch.Size([1, 30, 31, 10])\n",
      "y torch.Size([1, 30, 31, 10]) += r_2 : torch.Size([1, 30, 31, 10])\n",
      "y_2 : torch.Size([1, 30, 63, 10])\n",
      "y torch.Size([1, 30, 63, 10]) += r_3 : torch.Size([1, 30, 63, 10])\n",
      "y_3 : torch.Size([1, 30, 128, 10])\n",
      "y torch.Size([1, 30, 128, 10]) += r_4 : torch.Size([1, 30, 128, 10])\n",
      "y_4 : torch.Size([1, 30, 257, 10])\n",
      "y torch.Size([1, 30, 257, 10]) += r_5 : torch.Size([1, 30, 257, 10])\n",
      "y_5 : torch.Size([1, 30, 257, 10])\n",
      "torch.Size([1, 1, 257, 10])\n"
     ]
    }
   ],
   "source": [
    "m = ResUNetOnFreq2(c_in = 1, print_shape=True, activation = \"Sigmoid\",bottleneck = \"FTGRU\",multi_scale=True)\n",
    "m.eval()\n",
    "\n",
    "# to check low latency\n",
    "x = torch.rand(1,1,257,1)\n",
    "m(x)\n",
    "print(\"--------------------\")\n",
    "\n",
    "x = torch.rand(1,1,257,10)\n",
    "print(x.shape)\n",
    "y = m(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16343a0f-a7ff-4e9a-99ac-129288776fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_0 : torch.Size([1, 30, 257, 1])\n",
      "x_1 : torch.Size([1, 30, 128, 1])\n",
      "x_2 : torch.Size([1, 30, 63, 1])\n",
      "x_3 : torch.Size([1, 30, 31, 1])\n",
      "x_4 : torch.Size([1, 30, 15, 1])\n",
      "x_5 : torch.Size([1, 30, 7, 1])\n",
      "TGRU::torch.Size([7, 1, 256])\n",
      "y torch.Size([1, 30, 7, 1]) += r_0 : torch.Size([1, 30, 7, 1])\n",
      "y_0 : torch.Size([1, 30, 15, 1])\n",
      "y torch.Size([1, 30, 15, 1]) += r_1 : torch.Size([1, 30, 15, 1])\n",
      "y_1 : torch.Size([1, 30, 31, 1])\n",
      "y torch.Size([1, 30, 31, 1]) += r_2 : torch.Size([1, 30, 31, 1])\n",
      "y_2 : torch.Size([1, 30, 63, 1])\n",
      "y torch.Size([1, 30, 63, 1]) += r_3 : torch.Size([1, 30, 63, 1])\n",
      "y_3 : torch.Size([1, 30, 128, 1])\n",
      "y torch.Size([1, 30, 128, 1]) += r_4 : torch.Size([1, 30, 128, 1])\n",
      "y_4 : torch.Size([1, 30, 257, 1])\n",
      "y torch.Size([1, 30, 257, 1]) += r_5 : torch.Size([1, 30, 257, 1])\n",
      "y_5 : torch.Size([1, 30, 257, 1])\n",
      "--------------------\n",
      "torch.Size([1, 1, 257, 10])\n",
      "x_0 : torch.Size([1, 30, 257, 10])\n",
      "x_1 : torch.Size([1, 30, 128, 10])\n",
      "x_2 : torch.Size([1, 30, 63, 10])\n",
      "x_3 : torch.Size([1, 30, 31, 10])\n",
      "x_4 : torch.Size([1, 30, 15, 10])\n",
      "x_5 : torch.Size([1, 30, 7, 10])\n",
      "TGRU::torch.Size([7, 10, 256])\n",
      "y torch.Size([1, 30, 7, 10]) += r_0 : torch.Size([1, 30, 7, 10])\n",
      "y_0 : torch.Size([1, 30, 15, 10])\n",
      "y torch.Size([1, 30, 15, 10]) += r_1 : torch.Size([1, 30, 15, 10])\n",
      "y_1 : torch.Size([1, 30, 31, 10])\n",
      "y torch.Size([1, 30, 31, 10]) += r_2 : torch.Size([1, 30, 31, 10])\n",
      "y_2 : torch.Size([1, 30, 63, 10])\n",
      "y torch.Size([1, 30, 63, 10]) += r_3 : torch.Size([1, 30, 63, 10])\n",
      "y_3 : torch.Size([1, 30, 128, 10])\n",
      "y torch.Size([1, 30, 128, 10]) += r_4 : torch.Size([1, 30, 128, 10])\n",
      "y_4 : torch.Size([1, 30, 257, 10])\n",
      "y torch.Size([1, 30, 257, 10]) += r_5 : torch.Size([1, 30, 257, 10])\n",
      "y_5 : torch.Size([1, 30, 257, 10])\n",
      "torch.Size([1, 1, 257, 10])\n"
     ]
    }
   ],
   "source": [
    "m = ResUNetOnFreq2(c_in = 1, print_shape=True, activation = \"Sigmoid\",bottleneck = \"FTGRU\")\n",
    "m.eval()\n",
    "\n",
    "# to check low latency\n",
    "x = torch.rand(1,1,257,1)\n",
    "m(x)\n",
    "print(\"--------------------\")\n",
    "\n",
    "x = torch.rand(1,1,257,10)\n",
    "print(x.shape)\n",
    "y = m(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f440e491-154e-405d-8c56-2e48f94b5a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_0 : torch.Size([1, 30, 257, 1])\n",
      "x_1 : torch.Size([1, 30, 128, 1])\n",
      "x_2 : torch.Size([1, 30, 63, 1])\n",
      "x_3 : torch.Size([1, 30, 31, 1])\n",
      "x_4 : torch.Size([1, 30, 15, 1])\n",
      "x_5 : torch.Size([1, 30, 7, 1])\n",
      "y torch.Size([1, 30, 7, 1]) += r_0 : torch.Size([1, 30, 7, 1])\n",
      "y_0 : torch.Size([1, 30, 15, 1])\n",
      "y torch.Size([1, 30, 15, 1]) += r_1 : torch.Size([1, 30, 15, 1])\n",
      "y_1 : torch.Size([1, 30, 31, 1])\n",
      "y torch.Size([1, 30, 31, 1]) += r_2 : torch.Size([1, 30, 31, 1])\n",
      "y_2 : torch.Size([1, 30, 63, 1])\n",
      "y torch.Size([1, 30, 63, 1]) += r_3 : torch.Size([1, 30, 63, 1])\n",
      "y_3 : torch.Size([1, 30, 128, 1])\n",
      "y torch.Size([1, 30, 128, 1]) += r_4 : torch.Size([1, 30, 128, 1])\n",
      "y_4 : torch.Size([1, 30, 257, 1])\n",
      "y torch.Size([1, 30, 257, 1]) += r_5 : torch.Size([1, 30, 257, 1])\n",
      "y_5 : torch.Size([1, 30, 257, 1])\n",
      "--------------------\n",
      "torch.Size([1, 1, 257, 10])\n",
      "x_0 : torch.Size([1, 30, 257, 10])\n",
      "x_1 : torch.Size([1, 30, 128, 10])\n",
      "x_2 : torch.Size([1, 30, 63, 10])\n",
      "x_3 : torch.Size([1, 30, 31, 10])\n",
      "x_4 : torch.Size([1, 30, 15, 10])\n",
      "x_5 : torch.Size([1, 30, 7, 10])\n",
      "y torch.Size([1, 30, 7, 10]) += r_0 : torch.Size([1, 30, 7, 10])\n",
      "y_0 : torch.Size([1, 30, 15, 10])\n",
      "y torch.Size([1, 30, 15, 10]) += r_1 : torch.Size([1, 30, 15, 10])\n",
      "y_1 : torch.Size([1, 30, 31, 10])\n",
      "y torch.Size([1, 30, 31, 10]) += r_2 : torch.Size([1, 30, 31, 10])\n",
      "y_2 : torch.Size([1, 30, 63, 10])\n",
      "y torch.Size([1, 30, 63, 10]) += r_3 : torch.Size([1, 30, 63, 10])\n",
      "y_3 : torch.Size([1, 30, 128, 10])\n",
      "y torch.Size([1, 30, 128, 10]) += r_4 : torch.Size([1, 30, 128, 10])\n",
      "y_4 : torch.Size([1, 30, 257, 10])\n",
      "y torch.Size([1, 30, 257, 10]) += r_5 : torch.Size([1, 30, 257, 10])\n",
      "y_5 : torch.Size([1, 30, 257, 10])\n",
      "torch.Size([1, 1, 257, 10])\n"
     ]
    }
   ],
   "source": [
    "m = ResUNetOnFreq2(c_in = 1, print_shape=True, activation = \"Sigmoid\",bottleneck = \"LSTM\")\n",
    "m.eval()\n",
    "\n",
    "# to check low latency\n",
    "x = torch.rand(1,1,257,1)\n",
    "m(x)\n",
    "print(\"--------------------\")\n",
    "\n",
    "x = torch.rand(1,1,257,10)\n",
    "print(x.shape)\n",
    "y = m(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb68e3d-9d3c-4c8d-b8f0-397ab296c34a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
